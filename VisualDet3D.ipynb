{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg/12/daWL2mAfBPxFYCTV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilvecoding0912/Robotic-3D-Detection-In-Surgery/blob/main/VisualDet3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkr5vOqDhT_W",
        "outputId": "bd73fc85-0a2c-4882-d4d6-28c688103437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'visualDet3D'...\n",
            "remote: Enumerating objects: 308, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 308 (delta 80), reused 61 (delta 61), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (308/308), 24.75 MiB | 18.46 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Owen-Liuyuxuan/visualDet3D.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./make.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyRQVPtCi1W0",
        "outputId": "3dc73166-60ea-429f-cc24-68b32f321c34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/visualDet3D/visualDet3D/networks/lib/ops/dcn /content/visualDet3D\n",
            "running build_ext\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building '..deform_conv_ext' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.9\n",
            "creating build/temp.linux-x86_64-3.9/src\n",
            "creating build/temp.linux-x86_64-3.9/src/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -I/usr/local/cuda/include -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c src/cuda/deform_conv_cuda.cpp -o build/temp.linux-x86_64-3.9/src/cuda/deform_conv_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=deform_conv_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c src/cuda/deform_conv_cuda_kernel.cu -o build/temp.linux-x86_64-3.9/src/cuda/deform_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=deform_conv_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/irange.h(54)\u001b[0m: \u001b[01;35mwarning\u001b[0m #186-D: pointless comparison of unsigned integer with zero\n",
            "          detected during:\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "(61): here\u001b[0m\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "/usr/local/lib/python3.9/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.9/dist-packages/torch/include/c10/util/irange.h(54)\u001b[0m: \u001b[01;35mwarning\u001b[0m #186-D: pointless comparison of unsigned integer with zero\n",
            "          detected during:\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "(61): here\u001b[0m\n",
            "            instantiation of \u001b[01m\"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\u001b[0m \u001b[32m\n",
            "/usr/local/lib/python3.9/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\u001b[0m\n",
            "\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -I/usr/local/cuda/include -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c src/deform_conv_ext.cpp -o build/temp.linux-x86_64-3.9/src/deform_conv_ext.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=deform_conv_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "creating build/lib.linux-x86_64-3.9\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -I/usr/local/cuda/include -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/src/cuda/deform_conv_cuda.o build/temp.linux-x86_64-3.9/src/cuda/deform_conv_cuda_kernel.o build/temp.linux-x86_64-3.9/src/deform_conv_ext.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.9/deform_conv_ext.cpython-39-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.9/deform_conv_ext.cpython-39-x86_64-linux-gnu.so -> \n",
            "/content/visualDet3D\n",
            "/content/visualDet3D/visualDet3D/networks/lib/ops/iou3d /content/visualDet3D\n",
            "running build_ext\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building '..iou3d_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.9\n",
            "creating build/temp.linux-x86_64-3.9/src\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fopenmp -I/usr/local/cuda/include -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c src/iou3d.cpp -o build/temp.linux-x86_64-3.9/src/iou3d.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=iou3d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/usr/local/lib/python3.9/dist-packages/torch/include -I/usr/local/lib/python3.9/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.9/dist-packages/torch/include/TH -I/usr/local/lib/python3.9/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.9 -c src/iou3d_kernel.cu -o build/temp.linux-x86_64-3.9/src/iou3d_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=iou3d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "creating build/lib.linux-x86_64-3.9\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -fopenmp -I/usr/local/cuda/include -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.9/src/iou3d.o build/temp.linux-x86_64-3.9/src/iou3d_kernel.o -L/usr/local/lib/python3.9/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.9/iou3d_cuda.cpython-39-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.9/iou3d_cuda.cpython-39-x86_64-linux-gnu.so -> \n",
            "/content/visualDet3D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/visualDet3D/demos/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkG2jS98hd-7",
        "outputId": "d4083bca-e0f7-4ca8-9c5a-8c967ceb57d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/visualDet3D/demos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "import importlib\n",
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision\n",
        "from visualDet3D.data.kitti.utils import write_result_to_file\n",
        "from visualDet3D.utils.utils import LossLogger, cfg_from_file\n",
        "from visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
        "from visualDet3D.networks.heads.anchors import Anchors\n",
        "from visualDet3D.networks.lib.fast_utils.hill_climbing import post_opt\n",
        "from visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
        "from visualDet3D.utils.utils import convertAlpha2Rot, convertRot2Alpha, draw_3D_box, compound_annotation\n",
        "import visualDet3D.data.kitti.dataset\n",
        "from visualDet3D.utils.timer import Timer\n",
        "from numba import jit\n",
        "from tqdm import tqdm\n",
        "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
        "\n",
        "cfg = cfg_from_file(\"../config/kitti_stereo.py\")\n",
        "is_test_train = True\n",
        "\n",
        "checkpoint_name = \"open_Stereo3D_latest.pth\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrZ_ZdEuhtz6",
        "outputId": "ff40b366-6c7b-4a6c-f08c-2667c44626de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
        "    drawed_image = image.copy()\n",
        "    for box2d in bboxes2d:\n",
        "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
        "    return drawed_image"
      ],
      "metadata": {
        "id": "oOyQAsA3iURH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.batch_size=1\n",
        "split_to_test='validation'\n",
        "\n",
        "is_test_train = split_to_test == 'training'\n",
        "if split_to_test == 'training':\n",
        "    dataset_name = cfg.data.train_dataset\n",
        "elif split_to_test == 'test':\n",
        "    dataset_name = cfg.data.test_dataset\n",
        "else:\n",
        "    dataset_name = cfg.data.val_dataset\n",
        "\n",
        "dataset = DATASET_DICT[dataset_name](\n",
        "        cfg, split_to_test\n",
        "        )\n",
        "\n",
        "if split_to_test=='training':\n",
        "    dataset_val = DATASET_DICT[cfg.data.val_dataset](\n",
        "            cfg, 'validation'\n",
        "            )\n",
        "    dataset.transform = dataset_val.transform\n",
        "    dataset.collate_fn = dataset_val.collate_fn\n",
        "\n",
        "\n",
        "\n",
        "detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
        "detector = detector.cuda()\n",
        "\n",
        "weight_path = os.path.join(cfg.path.checkpoint_path, checkpoint_name)\n",
        "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
        "new_dict = state_dict.copy()\n",
        "for key in state_dict:\n",
        "    if 'focalLoss' in key:\n",
        "        new_dict.pop(key)\n",
        "detector.load_state_dict(new_dict, strict=False)\n",
        "detector.eval().cuda()\n",
        "\n",
        "# testing pipeline\n",
        "test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
        "\n",
        "projector = BBox3dProjector().cuda()\n",
        "backprojector = BackProjection().cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "IYhb0ZJjk6Ir",
        "outputId": "d3c3f9fe-d8e3-46fd-e88a-8ee637617a82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-10bd49ab67ad>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m dataset = DATASET_DICT[dataset_name](\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_to_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         )\n",
            "\u001b[0;32m/content/visualDet3D/demos/../visualDet3D/data/kitti/dataset/mono_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, split)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mimdb_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imdb.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# list of kittiData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         self.output_dict = {\n\u001b[1;32m     47\u001b[0m                 \u001b[0;34m\"calib\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './workdirs/MonoDTR/output/validation/imdb.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "def corner_homo2bbox(corner_homo):\n",
        "    \"\"\"\n",
        "        corner_homo: [N, 8, 3]\n",
        "    \"\"\"\n",
        "    min_xy  = torch.min(corner_homo[:, :, 0:2], dim=1)[0]\n",
        "    max_xy  = torch.max(corner_homo[:, :, 0:2], dim=1)[0]\n",
        "    min_xy[:, 0]  = torch.clamp(min_xy[:, 0], 0, cfg.rgb_shape[1])\n",
        "    min_xy[:, 1]  = torch.clamp(min_xy[:, 1], 0, cfg.rgb_shape[0])\n",
        "    max_xy[:, 0]  = torch.clamp(max_xy[:, 0], 0, cfg.rgb_shape[1])\n",
        "    max_xy[:, 1]  = torch.clamp(max_xy[:, 1], 0, cfg.rgb_shape[0])\n",
        "    return torch.cat([min_xy, max_xy], dim=1)\n",
        "\n",
        "def denorm(image):\n",
        "    new_image = np.array((image * cfg.data.augmentation.rgb_std +  cfg.data.augmentation.rgb_mean) * 255, dtype=np.uint8)\n",
        "    return new_image\n",
        "\n",
        "@jit(cache=True, nopython=True)\n",
        "def ToColorDepth(depth_image:np.ndarray)->np.ndarray: #[H, W] -> [H, W, 3] # Used to draw depth predictions\n",
        "    H, W = depth_image.shape\n",
        "    max_depth = float(np.max(depth_image))\n",
        "    cmap = np.array([\n",
        "        [0,0,0,114],[0,0,1,185],[1,0,0,114],[1,0,1,174], \n",
        "        [0,1,0,114],[0,1,1,185],[1,1,0,114],[1,1,1,0]\n",
        "    ])\n",
        "    _sum  = 0\n",
        "    for i in range(8):\n",
        "        _sum += cmap[i, 3]\n",
        "    \n",
        "    weights = np.zeros(8)\n",
        "    cumsum = np.zeros(8)\n",
        "    for i in range(7):\n",
        "        weights[i] = _sum / cmap[i, 3]\n",
        "        cumsum[i+1] = cumsum[i] + cmap[i, 3] / _sum\n",
        "    \n",
        "    image = np.zeros((H, W, 3), dtype=np.uint8)\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            val = depth_image[i, j] / max_depth\n",
        "            for k in range(7):\n",
        "                if val <= cumsum[k + 1]:\n",
        "                    break\n",
        "            w = 1.0- (val - cumsum[k]) * weights[k]\n",
        "            r = int( (w * cmap[k, 0] + (1 - w) * cmap[k+1, 0]) * 255 )\n",
        "            g = int( (w * cmap[k, 1] + (1 - w) * cmap[k+1, 1]) * 255 )\n",
        "            b = int( (w * cmap[k, 2] + (1 - w) * cmap[k+1, 2]) * 255 )\n",
        "            image[i, j] = np.array([r,g,b])\n",
        "    return image"
      ],
      "metadata": {
        "id": "ehUvAEVwk6v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_once(index, is_draw=True, is_test_train=True):\n",
        "    name = \"%06d\" % index\n",
        "    data = dataset[index]\n",
        "    if isinstance(data['calib'], list):\n",
        "        P2 = data['calib'][0]\n",
        "    else:\n",
        "        P2 = data['calib']\n",
        "    original_height = data['original_shape'][0]\n",
        "    collated_data = dataset.collate_fn([data])\n",
        "    height = collated_data[0].shape[2]\n",
        "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
        "    \n",
        "    if len(collated_data) > 6:\n",
        "        left_images, right_images, _, _, labels, bbox_3d, _ = collated_data\n",
        "    else:\n",
        "        left_images, right_images, _, _, labels, bbox_3d = collated_data\n",
        "    image = left_images\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
        "        scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
        "                                          right_images.cuda().float().contiguous(),\n",
        "                                          P2.cuda().float(),\n",
        "                                          P3.cuda().float()])\n",
        "        \n",
        "        P2 = P2[0]\n",
        "        bbox_2d = bbox[:, 0:4]\n",
        "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
        "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
        "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
        "\n",
        "            \n",
        "    \n",
        "    rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
        "    if len(scores) > 0:\n",
        "        rgb_image = draw_bbox2d_to_image(rgb_image, bbox_2d.cpu().numpy())\n",
        "        for box in bbox_3d_corner_homo:\n",
        "            box = box.cpu().numpy().T\n",
        "            rgb_image = draw_3D_box(rgb_image, box)\n",
        "    if is_draw:\n",
        "        plt.imshow(np.clip(rgb_image, 0, 255))\n",
        "\n",
        "    return np.clip(rgb_image, 0, 255)\n",
        "    "
      ],
      "metadata": {
        "id": "YgUrcfG9lD4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 0\n",
        "a = compute_once(index)"
      ],
      "metadata": {
        "id": "N1CBwF0AlGU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%matplotlib inline\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "index += 1\n",
        "a = compute_once(index, is_test_train=False, is_draw=True)"
      ],
      "metadata": {
        "id": "6aVmVLeplJT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}